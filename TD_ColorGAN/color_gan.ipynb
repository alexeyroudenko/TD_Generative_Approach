{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###GAN With COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.406056Z",
     "start_time": "2023-07-28T06:03:07.391057Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "# from model import discriminator, generator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.407056Z",
     "start_time": "2023-07-28T06:03:07.397058Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.407056Z",
     "start_time": "2023-07-28T06:03:07.402056Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hyperparameter settings\n",
    "\"\"\"\n",
    "# Root directory for dataset\n",
    "dataroot = \"data/celeba\"\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "# Number of training epochs\n",
    "num_epochs = 500\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "latent_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.429056Z",
     "start_time": "2023-07-28T06:03:07.410056Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\"\"\"\n",
    "Network Architectures\n",
    "The following are the discriminator and generator architectures\n",
    "\"\"\"\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.429056Z",
     "start_time": "2023-07-28T06:03:07.416058Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "# from model import discriminator, generator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import cv2\n",
    "import torchvision\n",
    "avgpool = nn.AdaptiveAvgPool2d((64, 64))\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.429056Z",
     "start_time": "2023-07-28T06:03:07.417057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Determine if any GPUs are available\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model\n",
    "# G = generator().to(device)\n",
    "# D = discriminator().to(device)\n",
    "#\n",
    "# G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "# D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "\"\"\"\n",
    "Image transformation and dataloader creation\n",
    "Note that we are training generation and not classification, and hence\n",
    "only the train_loader is loaded\n",
    "\"\"\"\n",
    "# Transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.432057Z",
     "start_time": "2023-07-28T06:03:07.421057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avgpool = nn.AdaptiveAvgPool2d((64, 64))\n",
    "dataset = './datasets/twimg_64/'\n",
    "\n",
    "class afhqDataset(Dataset):\n",
    "    def __init__(self, root_dir=dataset):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_dir = root_dir + '*.png'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(glob.glob(self.img_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(glob.glob(self.img_dir)[idx])/255.\n",
    "        image = torch.Tensor(image)\n",
    "        image = image.permute(2, 0, 1)\n",
    "        image = avgpool(image)\n",
    "        return image\n",
    "\n",
    "train_set = afhqDataset()\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:07.524057Z",
     "start_time": "2023-07-28T06:03:07.433057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(glob.glob(dataset + '/*')[1])/255.\n",
    "image = torch.Tensor(image)\n",
    "image = image.permute(2, 0, 1)\n",
    "image = avgpool(image)\n",
    "image = image.permute(1, 2, 0)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:08.368057Z",
     "start_time": "2023-07-28T06:03:07.520056Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.02.\n",
    "netG.apply(weights_init)\n",
    "# Print the model\n",
    "#print(netG)\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "# Print the model\n",
    "#print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:03:08.372056Z",
     "start_time": "2023-07-28T06:03:08.367057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:13:22.804056Z",
     "start_time": "2023-07-28T06:03:08.375057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for idx, (imgs) in enumerate(train_loader):\n",
    "        idx += 1\n",
    "\n",
    "        # Training the discriminator\n",
    "        # Real inputs are actual images of the MNIST dataset\n",
    "        # Fake inputs are from the generator\n",
    "        # Real inputs should be classified as 1 and fake as 0\n",
    "        real_inputs = imgs.to(device)\n",
    "        real_outputs = netD(real_inputs)\n",
    "        real_label = torch.ones(real_inputs.shape[0], 1).to(device)\n",
    "\n",
    "        noise = (torch.rand(real_inputs.shape[0], 100, 1, 1) - 0.5) / 0.5\n",
    "        noise = noise.to(device)\n",
    "#         print(noise.shape)\n",
    "        fake_inputs = netG(noise)\n",
    "        fake_outputs = netD(fake_inputs)\n",
    "        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\n",
    "\n",
    "        outputs = torch.cat((real_outputs.view(-1).unsqueeze(1), fake_outputs.view(-1).unsqueeze(1)), 0)\n",
    "        targets = torch.cat((real_label, fake_label), 0)\n",
    "\n",
    "        D_loss = loss(outputs, targets)\n",
    "        optimizerD.zero_grad()\n",
    "        D_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Training the generator\n",
    "        # For generator, goal is to make the discriminator believe everything is 1\n",
    "        noise = (torch.rand(real_inputs.shape[0], 100, 1, 1)-0.5)/0.5\n",
    "        noise = noise.to(device)\n",
    "#         print(noise.shape)\n",
    "        fake_inputs = netG(noise)\n",
    "        fake_outputs = netD(fake_inputs)\n",
    "        fake_targets = torch.ones([fake_inputs.shape[0], 1]).to(device)\n",
    "        G_loss = loss(fake_outputs.view(-1).unsqueeze(1), fake_targets)\n",
    "        optimizerG.zero_grad()\n",
    "        G_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if idx % 10 == 0 or idx == len(train_loader):\n",
    "            print('Epoch {} Iteration {}: discriminator_loss {:.3f} generator_loss {:.3f}'.format(epoch, idx, D_loss.item(), G_loss.item()))\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(\"save models\")\n",
    "        # Save the model checkpoints\n",
    "        torch.save(netG.state_dict(), f'./models/micro_64_{epoch}_G.ckpt')\n",
    "        torch.save(netD.state_dict(), f'./models/micro_64_{epoch}_D.ckpt')\n",
    "    #     torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n",
    "    #     print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:13:22.933056Z",
     "start_time": "2023-07-28T06:13:22.805056Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    torch.manual_seed(i)\n",
    "    noise = (torch.rand(real_inputs.shape[0], 100, 1, 1) - 0.5) / 0.5\n",
    "    noise = noise.to(device)\n",
    "    output = netG(noise)\n",
    "    plt.imshow(output[0].permute(1, 2, 0).detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T06:13:22.933056Z",
     "start_time": "2023-07-28T06:13:22.931057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import torchvision.transforms as T\n",
    "# transformim = T.ToPILImage()\n",
    "#\n",
    "# G = torch.load('midigan_19.pth')\n",
    "# G.eval()\n",
    "#\n",
    "# for seed in range(0,5):\n",
    "#     torch.manual_seed(seed)\n",
    "#     noise = (torch.rand(1, latent_size)-0.5)/0.5\n",
    "#     noise = noise.to(device)\n",
    "#     generated = G(noise)\n",
    "#     generated = generated.cpu().detach()\n",
    "#     img = generated[0].reshape(image_size, image_size)\n",
    "#     img = transformim(img)\n",
    "#     display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
