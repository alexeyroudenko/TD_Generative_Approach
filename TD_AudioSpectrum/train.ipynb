{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generative parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"spectrum\",  \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.001,\n",
    "#     \"architecture\": \"SpectrumEncoder\",\n",
    "#     \"dataset\": \"Spectrum Dataset\",\n",
    "#     \"epochs\": 50,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "dataset = np.loadtxt('spectrum_dataset.3.csv', delimiter='\\t')\n",
    "X = dataset[:,0:64]\n",
    "y = dataset[:,64:68]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class SpectrumEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(64, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(256, 4)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = SpectrumEncoder()\n",
    "print(model)\n",
    "        \n",
    "# train the model\n",
    "loss_fn   = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100 \n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % batch_size == 0:\n",
    "        print(f'Epoch : {epoch}, Training: Loss: {loss}')\n",
    "        # wandb.log({'epoch': epoch, 'loss': loss})\n",
    "\n",
    "\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = model(X) #(model(X) > 0.5).float()\n",
    "for i in range(10):\n",
    "    # print(type(predictions[i]), type(y[i]))\n",
    "    a = predictions[i]\n",
    "    b = y[i]\n",
    "    distance = torch.sqrt(torch.sum(torch.pow(torch.subtract(a, b), 2), dim=0))\n",
    "    #print('%s => %s' % (y[i].tolist(), predictions[i].tolist()))\n",
    "    print(f\"{i} distance: {distance} {a}\")\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = model(X) #(model(X) > 0.5).float()\n",
    "for i in range(10):\n",
    "    # print(type(predictions[i]), type(y[i]))\n",
    "    a = predictions[i]\n",
    "    b = y[i]\n",
    "    distance = torch.sqrt(torch.sum(torch.pow(torch.subtract(a, b), 2), dim=0))\n",
    "    #print('%s => %s' % (y[i].tolist(), predictions[i].tolist()))\n",
    "    print(f\"{i} distance: {distance} {a} {b}\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'spectrum.model')\n",
    "\n",
    "# import wandb\n",
    "# import random\n",
    "# # Start a new W&B run\n",
    "# with wandb.init(project=\"spectrum\") as run:\n",
    "#     # Simulate logging model metrics\n",
    "#     run.log({\"acc\": random.random()})\n",
    "#     # Save the dummy model to W&B\n",
    "#     best_model = wandb.Artifact(f\"model_{run.id}\", type=\"model\")\n",
    "#     best_model.add_file(\"spectrum.h5\")\n",
    "#     run.log_artifact(best_model)\n",
    "#     # Link the model to the Model Registry\n",
    "#     run.link_artifact(best_model, \"model-registry/My Registered Model\")\n",
    "#     run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from autoPyTorch import AutoNetClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.onnx.export(model, X, 'spectrum.onnx', input_names=[\"features\"], output_names=[\"logits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T09:13:08.321573Z",
     "start_time": "2023-08-30T09:13:08.289572Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'spectrum.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "inference_playground (5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
